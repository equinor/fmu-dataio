#!/usr/bin/env python

"""Updates the schemas for both the dev environment and the staging/production
environment.

To prepare the schemas for release, prepend an environment variable to the command:

    $ SCHEMA_RELEASE=1 ./tools/update-schema --diff

This will compare the schemas with all $id URLs removed, which in theory can be present
anywhere in any schema.
"""

from __future__ import annotations

import argparse
import difflib
import json
import os
import subprocess
import sys
from copy import deepcopy
from pathlib import Path
from typing import TYPE_CHECKING, Any, Dict, List, TypeVar

if TYPE_CHECKING:
    from fmu.dataio._models._schema_base import SchemaBase

GREEN = "\033[32m"
RED = "\033[31m"
YELLOW = "\033[93m"
NC = "\033[0m"
BOLD = "\033[1m"
PASS = f"[{BOLD}{GREEN}âœ”{NC}]"
FAIL = f"[{BOLD}{RED}âœ–{NC}]"
INFO = f"[{BOLD}{YELLOW}+{NC}]"

T = TypeVar("T", Dict, List, object)


def _get_parser() -> argparse.ArgumentParser:
    """Construct parser object."""
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "-d",
        "--diff",
        action="store_true",
        help="Show a diff between the current schema and the new one in output.",
    )
    parser.add_argument(
        "-p",
        "--prod",
        action="store_true",
        help="Produce schemas with production URLs",
    )
    parser.add_argument(
        "-t",
        "--test",
        action="store_true",
        help="Run as normal, but don't write the file.",
    )
    parser.add_argument(
        "-f",
        "--force",
        action="store_true",
        help="Force the script to overwrite the current schema with the new schema.",
    )
    return parser


def _load_json(filepath: Path) -> dict[str, Any]:
    with open(filepath, encoding="utf-8") as f:
        try:
            return json.load(f)
        except json.JSONDecodeError as json_decode_error:
            print(
                FAIL,
                "Parsing existing json schema failed: The json is malformed."
                " If you know why, re-run the command with argument '--force' "
                "to overwrite with the new schema.\n"
                f"{FAIL} json parsing error: '{json_decode_error.msg}.'",
            )
            sys.exit(1)


def _get_output_filepath(schema_path: Path) -> Path:
    """Returns a Path with the appropriate output location, without the filename."""
    project_root = Path(__file__).parent.parent.resolve()  # absolute path of ../../
    return project_root / schema_path


def _check_output_path(dir_path: Path, is_test: bool) -> None:
    if dir_path.exists():
        if dir_path.is_dir():
            return
        print(
            FAIL,
            f"path '{dir_path}' exists but is not a directory, aborting. "
            "this needs to be fixed first.",
        )
        sys.exit(1)

    if not is_test:
        dir_path.mkdir(parents=True, exist_ok=True)
    print(INFO, f"created directory '{dir_path}'")


def _show_git_diff(output_filepath: Path) -> None:
    command = ["git", "diff", str(output_filepath)]
    print(INFO, f"running `{' '.join(command)}` ...")
    output = subprocess.run(command, capture_output=True, text=True)
    diff_str = "\n      ".join(output.stdout.split("\n"))
    print(f"      {diff_str}")  # To indent the first line too


def _show_py_diff(existing_schema: dict[str, Any], new_schema: dict[str, Any]) -> None:
    existing = json.dumps(existing_schema, indent=2, sort_keys=True)
    new = json.dumps(new_schema, indent=2, sort_keys=True)
    diff = difflib.unified_diff(
        existing.splitlines(),
        new.splitlines(),
        lineterm="",
        fromfile="existing schema",
        tofile="new schema",
    )
    diff_str = "\n      ".join(diff)
    print(f"      {diff_str}")


def _remove_schema_ids(schema: T) -> T:
    """Recursively remove all '$id' and 'url' fields from a schema."""
    if isinstance(schema, dict):
        return {
            key: _remove_schema_ids(value)
            for key, value in schema.items()
            if key not in ("$id", "url")
        }
    if isinstance(schema, list):
        return [_remove_schema_ids(item) for item in schema]
    return schema


def _schemas_without_ids_are_the_same(
    existing_schema: dict[str, Any],
    new_schema: dict[str, Any],
    is_release: bool,
    release_url: str,
) -> bool:
    """Checks that schemas are equivalent.

    If this is a release, it first removes all $id fields to ensure no other fields are
    being changed. It re-applies the root $id field (self-reference) to ensure that they
    do match.
    """
    if is_release:
        existing_schema = _remove_schema_ids(deepcopy(existing_schema))
        existing_schema["$id"] = release_url

        new_schema_id = new_schema["$id"]
        new_schema = _remove_schema_ids(deepcopy(new_schema))
        new_schema["$id"] = new_schema_id

    return existing_schema == new_schema


def write_schema(
    schema: SchemaBase,
    force_overwrite: bool,
    is_release: bool,
    is_test: bool,
    show_diff: bool,
) -> bool:
    output_filepath = _get_output_filepath(schema.PATH)
    _check_output_path(output_filepath.parent, is_test)

    new_schema = schema.dump()
    existing_schema = _load_json(output_filepath)

    if output_filepath.exists():
        if not force_overwrite and not _schemas_without_ids_are_the_same(
            existing_schema, new_schema, is_release, schema.url()
        ):
            print(
                FAIL,
                f"ðŸš¨ {BOLD}{schema.FILENAME}{NC} version {BOLD}{schema.VERSION}{NC} "
                "has changed. does it need a new version?",
            )
            if show_diff:
                _show_py_diff(existing_schema, new_schema)
            return False

        if (
            is_release
            and not force_overwrite
            and existing_schema["$id"] != new_schema["$id"]
        ):
            print(
                FAIL,
                f"ðŸš¨ {BOLD}{schema.FILENAME}{NC} version "
                f"{BOLD}{schema.VERSION}{NC}: mismatch in '$id'. you probably need "
                "to run `./tools/update-schema --prod --force`",
            )
            if show_diff:
                _show_py_diff(existing_schema, new_schema)
            return False
        if new_schema == existing_schema:
            print(
                PASS,
                f"{BOLD}{schema.FILENAME}{NC} version "
                f"{BOLD}{schema.VERSION}{NC} unchanged",
            )
            return True

    if not is_test:
        with open(output_filepath, "w", encoding="utf-8") as f:
            f.write(json.dumps(new_schema, indent=2, sort_keys=True))

    print(
        PASS,
        f"{BOLD}{schema.FILENAME}{NC} version {BOLD}{schema.VERSION}{NC} "
        f"written to:\n      {output_filepath}",
    )

    if show_diff:
        _show_git_diff(output_filepath)
    return True


def main() -> None:
    parser = _get_parser()
    args = parser.parse_args()

    if args.force:
        print(INFO, "forcing overwrite of all schemas")

    os.environ["DEV_SCHEMA"] = "" if args.prod else "1"
    # Ensures URLs will differ based on above
    import fmu.dataio._models as models

    failed_a_write = False
    for schema in models.schemas:
        did_write = write_schema(schema, args.force, args.prod, args.test, args.diff)
        if not did_write:
            failed_a_write = True

    if failed_a_write:
        sys.exit(1)


if __name__ == "__main__":
    main()
